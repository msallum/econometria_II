---
title: "Econometria 2"
author: "Miguel Sallum"
date: "23/06/2021"
output: pdf_document
header-includes:
- \usepackage[brazilian]{babel} # idioma
- \usepackage[utf8]{inputenc}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```
```{r libraries}
library(tidyverse)
```
```{r dados , echo= FALSE}
n = 10000

dados <- tibble(
  X1 = rnorm(n),
  X2 = runif(n),
  X3 = X1*X2 + rnorm(n),
  dependente = X3 + X1 + rnorm(n))
```
## Regressão Linear e Estimação

A regressão linear é um modelo de relação entre variáveis, e pode ser chamado também de função de esperança condicional. Ela é tradicionalmente estimada com método dos mínimos quadrados ordinários, mas é equivalente por método dos momentos e (se não me engano) por máxima verossimilhança.

Caso tenhamos somente um regressor, estamos estimando a esperança condicional da forma
$$
E[Y|X]\ =\ \beta_0\ +\ \beta_1X
$$
Tradicionalmente, no entanto, representamos o modelo como
$$
Y\ =\ \beta_0\ +\ \beta_1X +\mu
$$
Onde $\mu$ são os fatores não observados. 
Para estimarmos as regressões, são necessárias algumas hipóteses:
1.
É importante lembrar que a regressão *não é* um modelo causal. Para ser causal, são necessárias algumas hipóteses a mais. Sendo flexível com notação, em geral nosso interesse é estimar o modelo causal
$$
E[Y|do(X)]\ =\ \beta_0\ +\ \beta_1X
$$
Queremos encontrar então o valor adequado de $\beta_1$, que seria o efeito médio de X sobre Y. para isso, precisamos da hipótese **(não-observável)** 
4. $Corr(X,\mu )=0$

### Estimação matricial

```{r lm matriz}

ols <- function(Y, X){
  X <- as.matrix(X)
  Y <- as.matrix(Y)
  Xt <- t(X)
  XtX <- Xt %*% X
  XtX_inv <- solve(XtX)
  
  XtX_inv %*% Xt %*% Y
}

SST <- function(Y) {Y - mean(Y) %>% t(.) %*% .}

res <- function(Y, X) {Y - (X %*% ols(Y, X))}

SSR <- function(Y, X) {t(res(Y, X)) %*% res(Y, X)}

R2 <- function(Y, X){
  X <- as.matrix(X)
  Y <- as.matrix(Y)
  
  1 - SSR(Y,X) /SST(Y)
}

vcov<- function(Y, X, robust = FALSE){
  
  k <- nrow(ols(Y, X))
  n <- length(Y)
  if (robust) {
    sigma2
    
  } else {
    sigma2 <- as.numeric(SSR(Y, X)/(n-k))*diag(nrow = k)
  }
  var_cov <- sigma2 %*% XtX_inv
  
}

```

### Métodos do R e Bibliotecas

Para rodar as regressões,podemos usar a função nativa *lm()*, em geral já em conjunção com *summary()* para termos os algumas caracteristicas importantes, como $R^2$, erros-padrão e significância assumindo homoscedasticidade. Caso estejamos usando tidyverse, podemos usar as funções assim:

```{r lm function}

#lm(dependente ~ regressores, data = dados)%>%
 # summary()

```
No entanto, na maior parte dos casos, a hipótese da homoscedasticidade é muito fort


## Potencial Outcomes

Potencial Outcomes é uma forma de pensar sobre causalidade usando de contrafactuais. A ideia é que teríamos a informação do resultado de cada indivíduo para cada nível de intervenção de X. Os exemplos do tema em geral são binários, **mas o método não se restringe a isso**. Em casos binários, podemos representar o resultado do individuo i caso ele receba o tratameto ($X=1$) como $Y_i^1$, e como $Y_i^0$ caso ele não seja tratado .

Trabalhando com esses dados hipotéticos surgem alguns conceitos interessantes:
$$
\begin{aligned}
Treatment\ Effect_i\ (TE_i)\ &=\ Y_i^1\ -\ Y_i^0 \\
Average\ Treatment\ Effect\ (ATE)\ &=\ E[Y^1 - Y^0]\ =\ E[Y^1] - E[Y^0]\\
Treatment\ Effect\ on\ the\ Treated\ (ATT)\ &=\ E[Y^1 - Y^0|\ Treatment = 1]\\
Treatment\ Effect\ on\ the\ Unreated\ (ATU)\ &=\ E[Y^1 - Y^0|\ Treatment = 0]
\end{aligned}
$$
```{r cars}
summary(cars)
```

## Matching e Estratificação

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.


## Regression Discontinuity Design

## Variável Instrumental

## Panel Data

## Diferenças-em-Diferenças

## Event Study, Two-Way Fixed Effects e Generalização de DiD